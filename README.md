# CV Benchmark Platform

An internal CV competition platform supporting Image Classification, Object Detection, and Image Segmentation tasks.

## ğŸš€ Quick Start

### Development Environment

# 1. Install dependencies
uv sync

# 2. Run migrations
uv run python manage.py migrate

# 3. Create superuser
uv run python manage.py createsuperuser

# 4. Start development server
uv run python manage.py runserver

# 5. (Another terminal) Start Q Worker
uv run python manage.py qcluster

Access http://127.0.0.1:8000/admin/ to enter the management back-end.

### Production Environment (Docker)

# 1. Copy environment variable template
cp .env.example .env

# 2. Edit .env with real settings

# 3. Start all services
docker-compose up -d

# 4. Create superuser
docker-compose exec web python manage.py createsuperuser

## ğŸ“ Project Structure

â”œâ”€â”€ config/                 # Django settings
â”œâ”€â”€ competitions/           # Competition core app
â”‚   â”œâ”€â”€ models.py          # Data models
â”‚   â”œâ”€â”€ admin.py           # Admin interface
â”‚   â”œâ”€â”€ views.py           # Participant interface
â”œâ”€â”€ scoring/               # Scoring engine
â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract base classes
â”‚   â””â”€â”€ tasks.py           # Django-Q2 async tasks
â”œâ”€â”€ templates/             # HTML templates
â”œâ”€â”€ tests/                 # Tests

## ğŸ† Features

### Organizer (Admin)
- Create competitions in Django Admin
- Set task types (Classification/Detection/Segmentation)
- Upload Ground Truth
- **Custom Scoring Scripts**: Upload Python scripts for complex scoring logic.
- Manage participant whitelist and specific time windows

### Participant
- Real-time countdown for remaining time
- Automatic scoring after prediction file upload
- **Detailed Logs**: View scoring logs and error messages in a modal.
- View submission history and Public Score
- Select final submission version

### Validator
- Enter Private Score directly in Admin portal
- Announce final rankings after competition ends

## ğŸ“Š Supported Metrics

| Task Type | Metric |
|-----------|--------|
| Classification | Accuracy, F1-Score |
| Detection | mAP@0.5, mAP@0.75, mAP@[0.5:0.95], Precision, Recall |
| Segmentation | mIoU |
| **All Tasks** | **Custom Script** (via Python upload) |

## ï¿½ï¸ Development Tools

To maintain high code quality and type safety, the following tools are used:

- **Linting & Formatting**: [Ruff](https://docs.astral.sh/ruff/)
  ```bash
  uv run ruff check .
  uv run ruff format .
  ```
- **Type Checking**: [ty](https://docs.astral.sh/ty/)
  ```bash
  uv run ty check
  ```

## ï¿½ğŸ“ CSV Format
(Details of CSV format)
